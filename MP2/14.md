
###### Relatório do 2º mini projeto de Língua Natural
- Rafael Candeias, 93748
- Vasco Piussa, 93762

#### BREVE INTRODUÇÃO
- Para a resolução do projeto que nos foi apresentado, após muita pesquisa e planeamento, criámos dois modelos diferentes, o M1 e o M2. Ambos possuem o mesmo ficheiro de treino e de teste, trainWithoutDev.txt e dev.txt, respetivamente, têm um funcionamento geral similar, e apresentam linha a linha no ficheiro results.txt a categoria que calcularam para cada par pegunta resposta do ficheiro input. 
- No que toca a avaliação, foi criado um ficheiro python que calcula a accuracy de cada modelo, comparando linha a linha a categoria no ficheiro de resultados com a do ficheiro de teste.

#### MODELS
- Tal como foi mencionado anteriormente, ambos os modelos funcionam superficialmente da mesma maneira.
    - Para cada linha do ficheiro de teste, aplicam um pre-processing para criar uma simplificação da string que retiram, e passam-na para o algoritmo que implementam. Ambos os algoritmos exercem cálculos entre a simplificação que recebem e as strings também simplificadas de todas as linhas do ficheiro de treino. 
    - Por fim, é posta a categoria calculada no ficheiro de respostas (results.txt).
- Pondo as suas semelhanças de parte, revelamos agora onde se diferem.
- O modelo M1 contém os seguintes atributos e métodos: uma lista para cada categoria, pergunta e resposta, um ficheiro de treino, um ficheiro de teste, um objeto que suporta o algoritmo Snowball Stemmer, um valor de threshold, um método stem que aplica o algoritmo Snowball Stemmer a uma frase e devolve a sua simplificação, 1 método jaccard que calcula a distância entre duas frases, e por fim um método compute que executa o modelo. A sua execução segue os seguintes passos:
    - Em primeiro lugar, dividimos cada linha do ficheiro de treino em três segmentos: categoria, pergunta e resposta. 
    - A categoria é adicionada a uma lista de categorias. Por outro lado, tanto a pergunta como a resposta são separadas palavra a palavra (tokenization). A cada palavra aplica-se o algoritmo Snowball Stemmer que a reduz à sua raíz (stemming), tal como demonstrado no seguinte exemplo: Snowball Stemmer("Programmers") = "program". Terminado o pre-processing, ambos os segmentos são adicionadas à sua lista.
    - De seguida, cada linha do ficheiro de teste também é dividida em 3 segmentos (categoria, pergunta e resposta). Ignorando o primeiro segmento, aplicamos o mesmo pre-processing aos restantes, (à pergunta e à resposta). Posteriormente, calculamos o jaccard da pergunta da atual linha do ficheiro de teste com todas as perguntas guardadas no atributo lista de perguntas. Caso o seu valor seja igual ou inferior à threshold selecionada, repetimos o processo com a pergunta seguinte no atributo lista de perguntas. Contudo, se não for o caso, aplica-se o jaccard entre a resposta da linha de teste com a resposta à pergunta atual da lista de perguntas. Somam-se os jaccards da pergunta e da resposta e reponde-se com a categoria da linha de treino que tiver a maior soma.
- No que toca o modelo M2, para realizar o pre-processing, utilizámos tokenization por palavra a palavra, o algoritmo Porter's Stemmer, stop words e stop chars. As stop chars seguem o mesmo conceito que as stop words, mas focam-se nos caractéres presentes numa palavra. Para calcular a probabilidade de uma linha ser de uma categoria, optámos por uma vertente do algoritmo Naïve Bayes, o Complement Naïve Bayes (CNB).
Este modelo contém um ficheiro de teste, um ficheiro de treino, um conjunto com todas as palavras existentes em cada categoria, um dicionário com o numero de palavras em cada categoria, um vocabulário, um atributo com o numero de palavras no vocabulario, um atributo com o numero de linhas do ficheiro de treino, um dicionário com a probabilidade de cada categoria, um conjunto de stopwords, um conjunto de stopchars, um objeto que suporta o algoritmo Porter's Stemmer, um método que realiza todo o pre-processing, excepto tokenization, um método que calcula a probabilidade de uma palavra não ser de uma categoria, um método que calcula a probabilidade do CNB e um método que executa o modelo.
O modelo inicia com a leitura de cada linha do ficheiro de treino e o seu pre-processing, onde reune informação necessária para o CNB. De seguida, aplica o CNB a cada linha do ficheiro de teste, e devolve a categoria que obteve a maior probabilidade.

#### EXPERIMENTAL SETUP
- Para o desenvolvimento do modelo M1, optámos por utilizar o algoritmo Jaccard, método que calcula a proximidade entre dois objetos a partir das suas semelhanças. O algoritmo segue a seguinte fórmula: |A.inter(B)|/|A.union(B)|. Tomámos esta decisão, uma vez que o algoritmo é rápido, intuitivo, fácil de implementar e suficiente para a baseline. Inicialmente, iámos utilizar o algoritmo Porter's Stemmer devido à sua fama e simplicidade. Com jaccard e Porter's Stemmer, obtivemos uma accuracy de 0.694, que é suficiente para a baseline pretendida. Contudo, após alguma investigação, deparámo-nos com um algoritmo mais otimizado e correto, tal como demonstrado nos seguintes exemplo: [ porter.stem('fairly') -> fairli;   snowball.stem('fairly') -> fair ]; [porter.stem('generically') -> gener;  porter.stem('generous') -> gener; snowball.stem('generically') -> generical; snowball.stem('generous') -> generous]. Deste modo, atualizámos o modelo e obtivémos uma accuracy final de 0.706.
- No que toca o desenvolvimento do modelo M2, inicialmente decimos utilzar o algoritmo Naive Bayes, método que aplica o teorem Bayes com a presunção "naive" da independencia condicional entre todos os pares de feature dados de um classe. O algoritmo segue a seguinte fórmula: P(Category|Line) = P(word0Line|Category)*P(word1Line|Category)*...*P(wordNLine|Category). Tomámos esta decisão, uma vez que o algoritmo é rápido, intuitivo, conhecido e facil de implementar. Para o Pre-processing, experimentamos a stemmatization com o Porter's Stemmer, Snowball Stemmer e Lancaster Stemmer. Com ele, obtivemos uma accuracy de 0.84

#### RESULTS
- Apesar das suas semelhanças, enquanto que o M1 alcança apenas uma precisão de 69.4% em 27.649 segundos, o M2 atinge uma precisão de 84.2% em 21.725 segundos.

#### ERROR ANALYSIS
Os erros mais comuns que encontramos foram: não usar as bibliotecas disponiveis e correr o risco de cometer erros a escrever o codigo manualmente, como pode ser visto no algoritmo Naive Bayes que implementamos.

#### FUTURE WORK
Se todos os jaccards derem <= ao threshold, nenhuma categoria é devolvida
Mais dados no geral
Equivaler as percentagens de categorias

#### BIBLIOGRAPHY
